{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "67WKXfi_nX2j",
        "AiJXaDNJnfLx",
        "ABS4ndCevv5Q",
        "ZjlDAHzn5kgW",
        "-r4W40oRBVmf",
        "FtELSbFanIpm"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d64fc1700f11468aa9ae9e90406c518a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a9a2ba03b334f6c98b3fc38a4d1e39c",
            "max": 3000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_576bfd3a24564c03a2e0f5f19b40a8a6",
            "value": 3000
          }
        },
        "4a9a2ba03b334f6c98b3fc38a4d1e39c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "576bfd3a24564c03a2e0f5f19b40a8a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a8c3afce5a440d7a1dcd783338c16b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f1d81efd39246c7a98af6586639e582",
            "max": 3000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5795fc1a3df64c6ab0362bdb87cc52d8",
            "value": 3000
          }
        },
        "3f1d81efd39246c7a98af6586639e582": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5795fc1a3df64c6ab0362bdb87cc52d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "087e02e1d27f427faf445c08900c5bc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43f521589feb4c4985aa9f8437ef3090",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18e7e8e2400c40f196791e9d5b7e0ff4",
            "value": 2000
          }
        },
        "43f521589feb4c4985aa9f8437ef3090": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18e7e8e2400c40f196791e9d5b7e0ff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "632586bbd27246b881b235e77d65cabb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_230b34cbb06d4dd19067ec13d9bacab1",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_145a7590b1494e079788e32290053f8c",
            "value": 2000
          }
        },
        "230b34cbb06d4dd19067ec13d9bacab1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "145a7590b1494e079788e32290053f8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Drive"
      ],
      "metadata": {
        "id": "67WKXfi_nX2j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akQbQOc4cHlT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41a8e7a3-933b-4b1c-e633-b750caa8bb95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import scipy.sparse as ss\n",
        "from scipy.stats import laplace\n",
        "from scipy.stats import norm as gaussian\n",
        "from scipy.optimize import lsq_linear\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "datadir = \"/content/drive/MyDrive/bu_dp_data\"\n",
        "if not os.path.exists(datadir):\n",
        "    os.mkdir(datadir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mechanisms\n"
      ],
      "metadata": {
        "id": "AiJXaDNJnfLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def l2_sensitivity(mymatrix):\n",
        "    x = mymatrix if type(mymatrix) == type(np.array([0])) else mymatrix.todense()\n",
        "    sens=np.sqrt(np.multiply(x,x).sum(axis=0).max())\n",
        "    return sens\n",
        "\n",
        "def l1_sensitivity(mymatrix):\n",
        "    x = mymatrix if type(mymatrix) == type(np.array([0])) else mymatrix.todense()    \n",
        "    sens=np.abs(x).sum(axis=0).max()\n",
        "    return sens\n",
        "\n",
        "def answer_query(query, data):\n",
        "    if type(query) == type(np.array([0])):\n",
        "      return query @ data # matrix multiplication in numpy\n",
        "    else:\n",
        "      return query * data # matrix multiplication in sparse matrices\n",
        "\n",
        "def laplace_mechanism(epsilon, query, data):\n",
        "    sens = l1_sensitivity(query)\n",
        "    scale = sens/epsilon\n",
        "    the_answer = answer_query(query, data)\n",
        "    return the_answer + laplace.rvs(scale=scale, size=the_answer.shape)\n",
        "\n",
        "def gaussian_mechanism(rho, query, data):\n",
        "    sens = l2_sensitivity(query)\n",
        "    scale = sens/np.sqrt(2*rho)\n",
        "    the_answer = answer_query(query, data)\n",
        "    return the_answer + gaussian.rvs(scale=scale, size=the_answer.shape)\n",
        "\n",
        "\n",
        "def postprocess(query, noisy_answer, nonneg=False):\n",
        "    \"\"\" Given a noisy answer to the query, estimate x using least squares and \n",
        "    optionally enforce nonnegativity\n",
        "    \"\"\"\n",
        "    if nonneg:\n",
        "        bounds = (0, np.inf)\n",
        "    else:\n",
        "        bounds = (-np.inf, np.inf)\n",
        "    solution_object = lsq_linear(query, noisy_answer, bounds=bounds)\n",
        "    return solution_object.x\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "njJiAtzphSui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code for running simulations\n"
      ],
      "metadata": {
        "id": "ABS4ndCevv5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ipywidgets import IntProgress\n",
        "from IPython.display import display\n",
        "\n",
        "def run_simulation(data, query, fname, amount=2000, mechanism=laplace_mechanism, param=0.25, savepoint = 1000, progress_interval=100):\n",
        "    \"\"\" Run query and postprocess simulations, returns their results\n",
        "    \n",
        "    Input:\n",
        "        data:  a data vector\n",
        "        query:  a set of queries represented as a matrix. query times data are the answers\n",
        "        fname: the base name of a file that will store the results of the simulation\n",
        "                set fname to None or \"\" to avoid any saving\n",
        "        amount: number of simulations to perform. It will read in any saved simulations and perform the remaining ones\n",
        "        mechanism: the function that provide the privacy protections (e.g,. laplace_mechanism or gaussian_mechanism)\n",
        "                mechanism is a funciton whose inputs are a privacy parameter, query, and data\n",
        "        param: privacy parameter for the mechanism\n",
        "        savepoint: save to google drive every `savepoint' simulations\n",
        "        progress_interval: update the progress bar every `progress_interval' simulations\n",
        "\n",
        "    output:\n",
        "        a list of noisy query answers\n",
        "        a list of ols postprocessed estimates of the data\n",
        "        a list of nnls postprocessed estimates of the data\n",
        "    \"\"\"\n",
        "    n = data.size\n",
        "\n",
        "    # see if loaded data exists\n",
        "    noisy_file = f\"{datadir}/{fname}_{n}_{mechanism.__name__}_{param}_na.npy\"\n",
        "    ols_file = f\"{datadir}/{fname}_{n}_{mechanism.__name__}_{param}_ols.npy\"\n",
        "    nnls_file = f\"{datadir}/{fname}_{n}_{mechanism.__name__}_{param}_nnls.npy\"\n",
        "    if os.path.exists(noisy_file):\n",
        "        noisy_arr = list(np.load(noisy_file))\n",
        "        ols_arr = list(np.load(ols_file))\n",
        "        nnls_arr = list(np.load(nnls_file))\n",
        "        #print(\"loading files ...\")\n",
        "        #print(\"loaded\", len(noisy_arr), \"simulations\")\n",
        "    else:\n",
        "        noisy_arr = []\n",
        "        ols_arr = []\n",
        "        nnls_arr = []\n",
        "    assert len(noisy_arr) == len(ols_arr) == len(nnls_arr)\n",
        "\n",
        "    starting = len(noisy_arr)\n",
        "    remaining = max(0, amount - len(noisy_arr))\n",
        "    #print(remaining, \"simulations remain\")\n",
        "    progress_bar = IntProgress(min=0, max=max(starting, amount))\n",
        "    display(progress_bar)\n",
        "    progress_bar.value = starting\n",
        "\n",
        "    for i in range(starting, amount):\n",
        "        noisy_answer = mechanism(param, query, data)\n",
        "        ols_solution = postprocess(query, noisy_answer, nonneg=False)\n",
        "        nnls_solution = postprocess(query, noisy_answer, nonneg=True)\n",
        "        noisy_arr.append(noisy_answer)\n",
        "        ols_arr.append(ols_solution)\n",
        "        nnls_arr.append(nnls_solution)\n",
        "        if i > 0 and i % savepoint == 0 and fname:\n",
        "            np.save(noisy_file, noisy_arr)\n",
        "            np.save(ols_file, ols_arr)\n",
        "            np.save(nnls_file, nnls_arr)\n",
        "        if i % progress_interval == 0:\n",
        "            progress_bar.value = i\n",
        "    progress_bar.value=max(starting, amount)\n",
        "    if fname:\n",
        "        np.save(noisy_file, noisy_arr)\n",
        "        np.save(ols_file, ols_arr)\n",
        "        np.save(nnls_file, nnls_arr)\n",
        "    return (noisy_arr, ols_arr, nnls_arr)\n",
        "\n",
        "    \n"
      ],
      "metadata": {
        "id": "Kc5zqGWhqVuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Minimizing sum squared error\n",
        "\n"
      ],
      "metadata": {
        "id": "ZjlDAHzn5kgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def experiment_ssq():\n",
        "    amount = 3000 # number of simulations\n",
        "    rho = 1\n",
        "    data = np.array([100, 200, 300, 400, 500])\n",
        "    workload_query = np.array([[1, 1, 1, 1, 1],\n",
        "                               [1, 0, 0, 0, 0],\n",
        "                               [0, 1, 0, 0, 0],\n",
        "                               [0, 0, 1, 0, 0],\n",
        "                               [0, 0, 0, 1, 0],\n",
        "                               [0, 0, 0, 0, 1]])\n",
        "    ###########################################################\n",
        "    # change this strategy_query (e.g, rescale rows, add rows)\n",
        "    ###########################################################\n",
        "    strategy_query = np.array([[1, 1, 1, 1, 1],\n",
        "                               [1, 0, 0, 0, 0],\n",
        "                               [0, 1, 0, 0, 0],\n",
        "                               [0, 0, 1, 0, 0],\n",
        "                               [0, 0, 0, 1, 0],\n",
        "                               [0, 0, 0, 0, 1]])\n",
        "    ###########################################################\n",
        "    (noisy_arr, ols_arr, nnls_arr) = run_simulation(data, strategy_query, fname=None, amount=amount, mechanism=gaussian_mechanism, param=rho)\n",
        "    true_answer = answer_query(workload_query, data)\n",
        "    ols_error = sum([((answer_query(workload_query, ans) - true_answer)**2).sum() for ans in ols_arr])/amount\n",
        "    print(f\"Your estimated error: {ols_error}\")\n",
        "    # compute optimal error:\n",
        "    betasq = 2 * rho\n",
        "    d = 5\n",
        "    a = (-3 + d) / (-1+d - np.sqrt(1+d)) / betasq\n",
        "    b = (-3 + d)*(2 - np.sqrt(1+d)) / (-1+d - np.sqrt(1+d)) / (-1-d + (-1+d)*np.sqrt(1+d)) / betasq\n",
        "    optimal_cost = d*(a+b) + d*a + d*d*b\n",
        "    print(f\"Optimal sum squared error is {optimal_cost}\")\n",
        "\n",
        "experiment_ssq()\n"
      ],
      "metadata": {
        "id": "6rbnraR45x36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "d64fc1700f11468aa9ae9e90406c518a",
            "4a9a2ba03b334f6c98b3fc38a4d1e39c",
            "576bfd3a24564c03a2e0f5f19b40a8a6"
          ]
        },
        "outputId": "b149afef-2ede-49db-b53c-46e6cc27f588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "IntProgress(value=0, max=3000)"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d64fc1700f11468aa9ae9e90406c518a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your estimated error: 5.034730326976701\n",
            "Optimal sum squared error is 4.159591794226543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hitting Error Targets"
      ],
      "metadata": {
        "id": "-r4W40oRBVmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def experiment_target():\n",
        "    amount = 3000 # number of simulations\n",
        "    rho = 1\n",
        "    data = np.array([100, 200, 300, 400, 500])\n",
        "    workload_query = np.array([[1, 1, 1, 1, 1],\n",
        "                               [1, 0, 0, 0, 0],\n",
        "                               [0, 1, 0, 0, 0],\n",
        "                               [0, 0, 1, 0, 0],\n",
        "                               [0, 0, 0, 1, 0],\n",
        "                               [0, 0, 0, 0, 1]])\n",
        "    ###########################################################\n",
        "    # change this strategy_query (e.g, rescale rows, add rows)\n",
        "    ###########################################################\n",
        "    strategy_query = np.array([[1, 1, 1, 1, 1],\n",
        "                               [1, 0, 0, 0, 0],\n",
        "                               [0, 1, 0, 0, 0],\n",
        "                               [0, 0, 1, 0, 0],\n",
        "                               [0, 0, 0, 1, 0],\n",
        "                               [0, 0, 0, 0, 1]])\n",
        "    ###########################################################\n",
        "    (noisy_arr, ols_arr, nnls_arr) = run_simulation(data, strategy_query, fname=None, amount=amount, mechanism=gaussian_mechanism, param=rho)\n",
        "    true_answer = answer_query(workload_query, data)\n",
        "    ols_error = sum([((answer_query(workload_query, ans) - true_answer)**2) for ans in ols_arr])/amount\n",
        "    print(f\"Your estimated errors: {ols_error}\")\n",
        "    # compute optimal error:\n",
        "    betasq = 2 * rho\n",
        "    d = 5\n",
        "    gamma = 2*d / (1+d) / betasq\n",
        "    optimal_cost = gamma\n",
        "    print(f\"Optimal target for each query is {optimal_cost}\")\n",
        "    print(f\"Targets exceeded by a factor of {ols_error.max()/gamma}\")\n",
        "\n",
        "experiment_target()\n"
      ],
      "metadata": {
        "id": "1yAouCj9BaP2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "1a8c3afce5a440d7a1dcd783338c16b6",
            "3f1d81efd39246c7a98af6586639e582",
            "5795fc1a3df64c6ab0362bdb87cc52d8"
          ]
        },
        "outputId": "68ec3c20-6879-4365-b635-98aa7d2a67ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "IntProgress(value=0, max=3000)"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a8c3afce5a440d7a1dcd783338c16b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your estimated errors: [0.85911868 0.79393816 0.7850811  0.84558753 0.81335281 0.86724989]\n",
            "Optimal target for each query is 0.8333333333333334\n",
            "Targets exceeded by a factor of 1.0406998675639156\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NNLS and OLS Comparisons\n",
        "\n"
      ],
      "metadata": {
        "id": "FtELSbFanIpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def identity_sum_query(n=1000):\n",
        "   \"\"\" returns a matrix like:\n",
        "   1 1 1 1\n",
        "   1 0 0 0\n",
        "   0 1 0 0 \n",
        "   0 0 1 0\n",
        "   0 0 0 1 where n is the number of columns\"\"\"\n",
        "   mat = np.vstack([np.ones(n), np.eye(n)])\n",
        "   return ss.csr_matrix(mat)\n",
        "\n",
        "def sample_data(n=1000, first=50):\n",
        "   data = np.zeros(n)\n",
        "   data[0]=50\n",
        "   return data\n",
        "\n",
        "def alternate_data(n=1000, first=50):\n",
        "   data = np.ones(n)\n",
        "   data[0]=50\n",
        "   return data\n",
        "\n"
      ],
      "metadata": {
        "id": "ofL1Ls0HeyDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questions to consider:\n",
        "\n",
        "\n",
        "1.   What utility measures should we use?\n",
        "2.   How do answers obtained from the OLS estimate of the data compare to the direct noisy answer?\n",
        "3.   How does NNLS accuracy compare to OLS accuracy? Are there any metrics where NNLS is better? Are there any metrics where OLS is better?\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zfeFP7OhEl71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 1000\n",
        "data = sample_data(n)\n",
        "query = identity_sum_query(n)\n",
        "(noisy_arr, ols_arr, nnls_arr) = run_simulation(data, query, \"id_sum_lap25\")\n",
        "\n",
        "data2 = alternate_data(n)\n",
        "(noisy_arr2, ols_arr2, nnls_arr2) = run_simulation(data2, query, \"alt_id_sum_lap25\")\n",
        "\n",
        "\n",
        "# noisy_arr[0] is a numpy array of noisy query answers for the first simulation\n",
        "# ols_arr[0] is an OLS estiamte of the data based on the noisy answers noisy_arr[0]\n",
        "# nnls_arr[0] is the corresponding nnls estimate\n",
        "# answer_query(query, ols_arr[0]) is the answer to the queries obtained from the first OLS estimate\n",
        "\n"
      ],
      "metadata": {
        "id": "5xalWuIwoJfM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79,
          "referenced_widgets": [
            "087e02e1d27f427faf445c08900c5bc0",
            "43f521589feb4c4985aa9f8437ef3090",
            "18e7e8e2400c40f196791e9d5b7e0ff4",
            "632586bbd27246b881b235e77d65cabb",
            "230b34cbb06d4dd19067ec13d9bacab1",
            "145a7590b1494e079788e32290053f8c"
          ]
        },
        "outputId": "80bf32ef-48f4-4a9a-bc94-4612cc52de35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "IntProgress(value=0, max=2000)"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "087e02e1d27f427faf445c08900c5bc0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "IntProgress(value=0, max=2000)"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "632586bbd27246b881b235e77d65cabb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are the error measures we are coding up"
      ],
      "metadata": {
        "id": "FC4nuOepFl0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First error measure\n",
        "\n",
        "def mean_squared_error(query, data, synth_arr):\n",
        "    true_answers = answer_query(query, data)\n",
        "    amount = len(synth_arr)\n",
        "    return sum([np.sum((answer_query(query, synth)-true_answers)**2) for synth in synth_arr]) / amount\n",
        "\n",
        "# second error measure\n",
        "def max_outlier_error(query, data, synth_arr):\n",
        "    true_answers = answer_query(query, data)\n",
        "    amount = len(synth_arr)\n",
        "    return sum([np.max((answer_query(query, synth) - true_answers)**2) for synth in synth_arr]) / amount\n",
        "\n",
        "# third error measure\n",
        "def max_expected_error(query, data, synth_arr):\n",
        "    true_answers = answer_query(query, data)\n",
        "    amount = len(synth_arr)\n",
        "    return max(sum([(answer_query(query, synth) - true_answers)**2 for synth in synth_arr]) / amount)\n",
        "\n",
        "# fourth error measure\n",
        "def max_bias_error(query, data, synth_arr):\n",
        "    true_answers = answer_query(query, data)\n",
        "    amount = len(synth_arr)\n",
        "    return max(np.abs(sum([answer_query(query, synth) - true_answers for synth in synth_arr])) / amount)\n",
        "\n",
        "# 5th error measure\n",
        "def look_at_three(query, data, synth_arr):\n",
        "    true_answers = answer_query(query, data)\n",
        "    amount = len(synth_arr)\n",
        "    first_three = sum([((answer_query(query, synth) - true_answers)**2)[0:3] for synth in synth_arr]) / amount\n",
        "    for x in first_three:\n",
        "         print(x)\n",
        "\n",
        "# 6th error measure\n",
        "def look_at_three_bias(query, data, synth_arr):\n",
        "    true_answers = answer_query(query, data)\n",
        "    amount = len(synth_arr)\n",
        "    first_three = sum([(answer_query(query, synth) - true_answers)[0:3] for synth in synth_arr]) / amount\n",
        "    for x in first_three:\n",
        "         print(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "d5SYYYymFwZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results:"
      ],
      "metadata": {
        "id": "3NocIOhnF2Y_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"OLS Sum Squared Error\", mean_squared_error(query, data, ols_arr)) \n",
        "print(\"NNLS Sum Squared Error\", mean_squared_error(query, data, nnls_arr))\n",
        "\n",
        "print(\"OLS outlier error\", max_outlier_error(query, data, ols_arr))\n",
        "print(\"NNLS outlier error\", max_outlier_error(query, data, nnls_arr))\n",
        "\n",
        "print(\"OLS max expected error\", max_expected_error(query, data, ols_arr))\n",
        "print(\"NNLS max expected error\", max_expected_error(query, data, nnls_arr))\n",
        "\n",
        "print(\"OLS max bias error\", max_bias_error(query, data, ols_arr))\n",
        "print(\"NNLS max bias error\", max_bias_error(query, data, nnls_arr))\n",
        "\n",
        "print(\"scale for comparison is \", np.sqrt(32))\n",
        "\n",
        "print(\"OLS look at 3\")\n",
        "look_at_three(query, data, ols_arr)\n",
        "print(\"NNLS look at 3\")\n",
        "look_at_three(query, data, nnls_arr)\n",
        "\n",
        "print(\"OLS look at 3 bias\")\n",
        "look_at_three_bias(query, data, ols_arr)\n",
        "print(\"NNLS look at 3 bias\")\n",
        "look_at_three_bias(query, data, nnls_arr)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAYmXbSFF3tw",
        "outputId": "72b7e51b-8c29-4c48-d321-00da3eb4a6bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OLS Sum Squared Error 127493.28808520139\n",
            "NNLS Sum Squared Error 3228.041737320452\n",
            "OLS outlier error 3620.0334912175504\n",
            "NNLS outlier error 1540.6200665928957\n",
            "OLS max expected error 147.82950425495594\n",
            "NNLS max expected error 1170.419725889349\n",
            "OLS max bias error 0.9207050375489471\n",
            "NNLS max bias error 32.477738599577336\n",
            "scale for comparison is  5.656854249492381\n",
            "OLS look at 3\n",
            "127.87008443666997\n",
            "123.3760430728707\n",
            "123.20262285502436\n",
            "NNLS look at 3\n",
            "1170.419725889349\n",
            "1140.625549791372\n",
            "0.3890884157590231\n",
            "OLS look at 3 bias\n",
            "-0.3815311266145748\n",
            "0.21942292943286607\n",
            "0.23852710365686444\n",
            "NNLS look at 3 bias\n",
            "32.477738599577336\n",
            "-32.3062635879303\n",
            "0.03863505106343246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Measuring error\n",
        "\n",
        "print(\"OLS Sum Squared Error\", mean_squared_error(query, data2, ols_arr2)) \n",
        "print(\"NNLS Sum Squared Error\", mean_squared_error(query, data2, nnls_arr2))\n",
        "\n",
        "print(\"OLS outlier error\", max_outlier_error(query, data2, ols_arr2))\n",
        "print(\"NNLS outlier error\", max_outlier_error(query, data2, nnls_arr2))\n",
        "\n",
        "print(\"OLS max expected error\", max_expected_error(query, data2, ols_arr2))\n",
        "print(\"NNLS max expected error\", max_expected_error(query, data2, nnls_arr2))\n",
        "\n",
        "print(\"OLS max bias error\", max_bias_error(query, data2, ols_arr2))\n",
        "print(\"NNLS max bias error\", max_bias_error(query, data2, nnls_arr2))\n",
        "\n",
        "print(\"scale for comparison is \", np.sqrt(32))\n",
        "\n",
        "print(\"OLS look at 3\")\n",
        "look_at_three(query, data2, ols_arr2)\n",
        "print(\"NNLS look at 3\")\n",
        "look_at_three(query, data2, nnls_arr2)\n",
        "\n",
        "print(\"OLS look at 3 bias\")\n",
        "look_at_three_bias(query, data2, ols_arr2)\n",
        "print(\"NNLS look at 3 bias\")\n",
        "look_at_three_bias(query, data2, nnls_arr2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-ATfqpvF3vx",
        "outputId": "67240e64-633e-4148-82ef-09139f9d72b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OLS Sum Squared Error 127807.94237388848\n",
            "NNLS Sum Squared Error 15733.100985631098\n",
            "OLS outlier error 3687.4332614820687\n",
            "NNLS outlier error 1944.907179529078\n",
            "OLS max expected error 146.63053477635512\n",
            "NNLS max expected error 268.3611301503197\n",
            "OLS max bias error 0.7475095526152166\n",
            "NNLS max bias error 12.152800628834381\n",
            "scale for comparison is  5.656854249492381\n",
            "OLS look at 3\n",
            "121.23601239672138\n",
            "127.1880916170575\n",
            "122.30989824087762\n",
            "NNLS look at 3\n",
            "268.3611301503197\n",
            "266.1891720118926\n",
            "15.794787033038672\n",
            "OLS look at 3 bias\n",
            "0.27306245471356466\n",
            "-0.09736579269559009\n",
            "0.4149287398135996\n",
            "NNLS look at 3 bias\n",
            "12.152800628834381\n",
            "-11.944933338489925\n",
            "0.034642179364533676\n"
          ]
        }
      ]
    }
  ]
}